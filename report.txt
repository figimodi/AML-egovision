PART 1
Starting from a pretrained model (I3D architecture)
we extract the features in this fashion:
1. For each sample (in the folder train_val) we take 5 clips, built in these different methods:
    a. using Dense or Uniform sampling
    b. Variating the number of frames per each clip (5, 10, 16, 25)
Once the features are extracted they're fed to a final classifier, which we built to be:
    a. MLP
    b. lstm
    c. RNN
TODO: check which configuration (sampling + network) was performing best

Also, given the extracted features we analyzed them by:
    1. applying PCA + K-means
    2. applyinh LDA
    3. applyin PCA+LDA
    4. applying TSNE

emg Pre-processing flow:
1. Apply low pass filter with cut frequency=5Hz, filter order=5 
    separately for each sample and for each arm
2. Apply scaling (see lines ~300 of process_emg) 
    separately for each sample analog for each arm
3. Reample the emg arm readings with a sample frequency of 10Hz
4. Augment the dataset in this fashion:
    a.subdivide each sample in 20 different new samples, each long 10s
    (these samples can overlap among each other)
5. Pad all the samples to make sure they have the same lenght so that
    they can be fed to the network: the padding is done by adding
    an even amount of zeors left and right
6. Spectograms are generated starting from each sample
7. For each sample generate the corresponding start and end frame number
    in the video 
8. An unique pickle file is created containing:
    a.emg sample
    b.frame numbers for rgb data
    c.spectogram image path
9. The train and test splits are balanced so each of them contain at least
    one sample for each class, in particular for each class the test set 
    must contain at least 0.05 times the samples in the train set
    (0.05 is a parameter that can be changed)

Other implementations that we tested:
1. Padding:
    a. noise (add left and right the mean value of the readings plus a gaussian noise mu=0, sigma=1)
    b. zeros left and right 
    c. mean (add left and right the mean value of the readings)
    d. zeros only on the right side
2. Filtering, normalization and scaling:
    a. applied separately for each sample for each arm
    b. applied channel-wise
    c. applied globally with statistics on all training set
3. Augmentation of the dataset:
    a. Subdivide each sample in chunks of x seconds each, not overlapping between each other.
        the number of subsamples depend on the duration of the original sample
    b. Subdivide each sample in N chunks of x seconds each, overlapping between each othre.
        the number of subsamples is N.
4. Generation of spectograms:
    TODO: stiv

EMG net:
only one lstm -> droput 20% -> relu -> fully connected
hidden_size = 50 

CNN net (sepcto):
TODO: stiv

RGB net (video):
TODO: pippo