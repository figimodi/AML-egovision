{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting started for the AML 2023/2024 Egocentric Vision Project"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EgovisionPolito/aml23-ego/blob/master/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installing missing dependencies\n",
        "# !pip install omegaconf coloredlogs wandb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EPIC-Kitchens-55 dataset\n",
        "\n",
        "**READ carefully!**\n",
        "\n",
        "To develop the project, you need to download the RGB frames for a subset of EPIC-Kitchens-55 (participants P08, P01 and P22) from [here](https://drive.google.com/drive/u/1/folders/1dJOtZ07WovP3YSCRAnU0E4gsfqDzpMVo). \n",
        "\n",
        "You also need to the pretrained checkpoints for each domain from [here](https://politoit-my.sharepoint.com/:f:/g/personal/simone_peirone_polito_it/ErdsZhvmR65Lun5_5O0-l5sBTPjCCZZq2f700Tj_CNzjTQ?e=L1yflf).\n",
        "\n",
        "Add the Google Drive directory containing the dataset to your Google Drive or upload the dataset on your Google Drive to access it from Google Colab.\n",
        "\n",
        "**NOTE**: As the dataset is quite heavy, we stronly suggest you to implement and test all your code on one for the three dataset. Then, once you are sure everything works, repeat the experiments on the remaining two datasets."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "88YghJyXhbfS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-02-17 16:17:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m Feature Extraction\n",
            "\u001b[32m2024-02-17 16:17:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m Running with parameters: \n",
            "  action: save\n",
            "  name: dense_5\n",
            "  modality: ['RGB']\n",
            "  total_batch: 128\n",
            "  batch_size: 32\n",
            "  gpus: None\n",
            "  wandb_name: None\n",
            "  resume_from: ./saved_models/I3D_SourceOnlyD1\n",
            "  logname: save_D1-D1.log\n",
            "  models_dir: saved_models\\dense_5\\Feb17_16-17-23\n",
            "  train:\n",
            "    num_iter: 5000\n",
            "    lr_steps: 3000\n",
            "    eval_freq: 50\n",
            "    num_clips: 1\n",
            "    dense_sampling:\n",
            "      RGB: True\n",
            "    num_frames_per_clip:\n",
            "      RGB: 16\n",
            "  test:\n",
            "    num_clips: 5\n",
            "    dense_sampling:\n",
            "      RGB: True\n",
            "    num_frames_per_clip:\n",
            "      RGB: 16\n",
            "  dataset:\n",
            "    annotations_path: train_val\n",
            "    shift: D1-D1\n",
            "    workers: 0\n",
            "    stride: 2\n",
            "    resolution: 224\n",
            "    RGB:\n",
            "      data_path: ../ek_data/frames\n",
            "      tmpl: img_{:010d}.jpg\n",
            "      features_name: test_feat_kinetics\n",
            "    Event:\n",
            "      rgb4e: 6\n",
            "  models:\n",
            "    RGB:\n",
            "      model: I3D\n",
            "      normalize: False\n",
            "      kwargs:\n",
            "      lr_steps: 3000\n",
            "      lr: 0.01\n",
            "      sgd_momentum: 0.9\n",
            "      weight_decay: 1e-07\n",
            "      dropout: 0.5\n",
            "      resolution: 224\n",
            "      weight_i3d_rgb: ./pretrained_i3d/rgb_imagenet.pt\n",
            "  split: train\n",
            "  save:\n",
            "    num_clips: 5\n",
            "    dense_sampling:\n",
            "      RGB: True\n",
            "    num_frames_per_clip:\n",
            "      RGB: 5\n",
            "  config: configs/I3D_save_feat.yaml\n",
            "  experiment_dir: dense_5\\Feb17_16-17-23\n",
            "  log_dir: TEST_RESULTS\\dense_5\n",
            "  logfile: TEST_RESULTS\\dense_5\\save_D1-D1.log\n",
            "\u001b[32m2024-02-17 16:17:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m Instantiating models per modality\n",
            "\u001b[32m2024-02-17 16:17:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m I3D Net\tModality: RGB\n",
            "\u001b[32m2024-02-17 16:17:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m Loading Kinetics weights I3D\n",
            "\u001b[32m2024-02-17 16:17:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m  * Skipping Logits weight for 'logits.conv3d.weight'\n",
            "\u001b[32m2024-02-17 16:17:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m  * Skipping Logits weight for 'logits.conv3d.bias'\n",
            "\u001b[32m2024-02-17 16:17:30\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m Restoring action-classifier for modality RGB from saved_models\\I3D_SourceOnlyD1\\Oct25_22-38-50\\action-classifier_RGB_9.pth\n",
            "\u001b[32m2024-02-17 16:17:30\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m RGB-Model for action-classifier restored at iter 4850.0\n",
            "Best accuracy on val: 59.54 at iter 4000.0\n",
            "Last accuracy on val: 58.85\n",
            "Last loss: 0.00\n",
            "\u001b[32m2024-02-17 16:17:30\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m Dataloader for D1-train with 1543 samples generated\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "python.exe save_feat.py name=uniform_5 \\\n",
        "  config=configs/I3D_save_feat.yaml \\\n",
        "  dataset.shift=D1-D1 \\\n",
        "  dataset.RGB.data_path=../ek_data/frames \\\n",
        "  split=train \\\n",
        "  dataset.workers=0 \\\n",
        "  save.num_frames_per_clip.RGB=5 \\\n",
        "  save.dense_sampling.RGB=False\n",
        "\n",
        "# python.exe save_feat.py name=uniform_25 config=configs/I3D_save_feat.yaml dataset.shift=D1-D1 dataset.RGB.data_path=../ek_data/frames split=test dataset.workers=0 save.num_frames_per_clip.RGB=25 save.dense_sampling.RGB=False\n",
        "# If everything is working, you should expect an error message telling you to implement the '_get_val_indices' method in the dataset class.\n",
        "# Once you have implemented it, you should run the script for the train and test split of the dataset to extract the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'use_frames': False, 'features_path': 'saved_features/uniform_5_D1_test.pkl', 'split_path': 'train_val/D1_test.pkl', 'output_image_path': 'plots/uniform/uniform_5_test_woim.png', 'plot_3D': False}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "B:\\Programmi\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "B:\\Programmi\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Figure(640x480)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "python.exe plot_features.py \\\n",
        "    use_frames=False \\\n",
        "    features_path='saved_features/uniform_5_D1_test.pkl' \\\n",
        "    split_path='train_val/D1_test.pkl' \\\n",
        "    output_image_path='plots/uniform/uniform_5_test_woim.png' \\\n",
        "    plot_3D=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "python.exe train_classifier.py \\\n",
        "    name=test_train \\\n",
        "    dataset.shift=D1-D1 \\\n",
        "    dataset.RGB.data_path=../ek_data/frames \\\n",
        "    dataset.RGB.features_name=SAVE_DENSE-extracted \\\n",
        "    dataset.workers=0 \\\n",
        "    # config=configs/I3D_save_feat.yaml \\\n",
        "    # action=train \\\n",
        "    # split=train \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
            "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings'],\n",
            "      dtype='object')\n",
            "[0, 29, 63, 94, 125, 155, 185, 224, 261, 292, 327, 366, 405, 448, 489, 528, 561, 591, 625, 655, 686, 717, 749, 782, 818, 851, 885, 918, 949, 982, 1015, 1047, 1081, 1115, 1148, 1176, 1203, 1238, 1275, 1316, 1355, 1396, 1435, 1474, 1517, 1556, 1585, 1620, 1655, 1686, 1717, 1751, 1782, 1814, 1845, 1873, 1906, 1937, 1969, 2002, 2036, 2068, 2101, 2134, 2163, 2201, 2238, 2270, 2301, 2337, 2379, 2415, 2450, 2489, 2525, 2554, 2584, 2614, 2646, 2677, 2708, 2739, 2774, 2807, 2839, 2870, 2903, 2934, 2970, 3004, 3032, 3063, 3097, 3128, 3162, 3199, 3240, 3275, 3314, 3352, 3391, 3432, 3470, 3507, 3538, 3571, 3603, 3632, 3668, 3697, 3730, 3763, 3796, 3831, 3862, 3897, 3929, 3962, 3994, 4024, 4056, 4086, 4120, 4158, 4199, 4240, 4275, 4315, 4354, 4393, 4431, 4473, 4512, 4542, 4575, 4609, 4641, 4673, 4707, 4739, 4767, 4797, 4830, 4859, 4890, 4918, 4951, 4983, 5015, 5049, 5084, 5111, 5141, 5171, 5208, 5247, 5286, 5325, 5365, 5402, 5443, 5484, 5521, 5551, 5582, 5617, 5646, 5677, 5712, 5743, 5777, 5806, 5838, 5872, 5904, 5932, 5964, 5999, 6032, 6065, 6099, 6134, 6171, 6206, 6238, 6271, 6314, 6353] 188\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(pd.read_pickle('./emg/S00_2.pkl'))\n",
        "l = list(data['myo_right_readings'][1:])\n",
        "first = l[0]\n",
        "first = abs(first)\n",
        "first = [2*(el-min(el))/(max(el)-min(el))-1 for el in first]\n",
        "# print(first)\n",
        "\n",
        "print(data.columns)\n",
        "freq = 5\n",
        "row = 3\n",
        "l = list(data['myo_right_timestamps'][1:])\n",
        "\n",
        "indexes = []\n",
        "for i in range(len(l[row])-1):\n",
        "    if cum > 1/freq or len(indexes) == 0:\n",
        "        indexes.append(i)\n",
        "        cum = 0\n",
        "    else:\n",
        "        cum += l[row][i+1]-l[row][i]\n",
        "\n",
        "print(indexes, len(indexes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.DataFrame(pd.read_pickle('./emg/S00_2.pkl'))\n",
        "\n",
        "fc = 5\n",
        "order = 4\n",
        "to_read = ['myo_right', 'myo_left']\n",
        "\n",
        "for side in to_read:\n",
        "    for i, _ in data.iterrows():\n",
        "        if i != 0:\n",
        "            # Rectify channels\n",
        "            row = abs(data.loc[i, side + '_readings'])\n",
        "            times = data.loc[i, side + '_timestamps']\n",
        "            \n",
        "            # Low-pass filter 5 Hz\n",
        "            fs = times.size / (times[-1]-times[0])\n",
        "\n",
        "            nyq = 0.5 * fs\n",
        "            wn = fc / nyq\n",
        "            \n",
        "            b, a = butter(order, wn, 'low', analog=False)\n",
        "            filtered = filtfilt(b, a, row.T).T\n",
        "            \n",
        "            # Normalize in [-1, 1]\n",
        "            scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "            filtered = scaler.fit_transform(filtered)\n",
        "            \n",
        "            # if row.size - filtered.size != 0:\n",
        "            #     print(row.size-filtered.size)\n",
        "            # if i == 1:\n",
        "            #     plt.plot(times, row[:, 0], label='Originali')\n",
        "            #     plt.plot(times, filtered[:, 0], label='Filtered')\n",
        "            #     plt.grid(True)\n",
        "            #     plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMA44pwS84HIKtaEclSmH2W",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.11.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "2802aa912f20f04bdfa864fece71ae8a7c06c1db711e2d82eab687200680d432"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
